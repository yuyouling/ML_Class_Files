{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3: Titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew (32% survival rate). This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been split into two groups:\n",
    "\n",
    "training set (titanic_train.csv)\n",
    "test set (titanic_test.csv)\n",
    "\n",
    "The training set should be used to build your machine learning models. The training set includes the target (outcome) value for each passenger. Your model will be based on “features” like the passengers’ gender and class. You can also use feature engineering to create new features.\n",
    "\n",
    "The test set should be used to see how well your model performs on unseen data. The test set lacks the target variable. It is the task of your model to predict these outcomes. For each passenger in the test set, use the model you trained to predict whether or not they survived the sinking of the Titanic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Survived: 0 = No, 1 = Yes\n",
    "\n",
    "Pclass: class 1 = 1st, 2 = 2nd, 3 = 3rd \n",
    "\n",
    "Sex: gender\n",
    "\n",
    "Age: Age in years \n",
    "\n",
    "SibSp: # of siblings / spouses aboard the Titanic\n",
    "\n",
    "Parch: # of parents / children aboard the Titanic \n",
    "\n",
    "Ticket: ticket number\n",
    "\n",
    "Fare: Passenger fare \n",
    "\n",
    "Cabin: Cabin number \n",
    "\n",
    "Embarked: Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "\n",
    "   **Variable Notes**\n",
    "   \n",
    "pclass: A proxy for socio-economic status (SES)\n",
    "1st = Upper\n",
    "2nd = Middle\n",
    "3rd = Lower\n",
    "\n",
    "Age: Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n",
    "\n",
    "SibSp: The dataset defines family relations in this way...\n",
    "Sibling = brother, sister, stepbrother, stepsister\n",
    "Spouse = husband, wife (mistresses and fiancés were ignored)\n",
    "\n",
    "Parch: The dataset defines family relations in this way...\n",
    "Parent = mother, father\n",
    "Child = daughter, son, stepdaughter, stepson\n",
    "Some children travelled only with a nanny, therefore Parch=0 for them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the features\n",
    "Note which are numerical and which are categorical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of numerical features\n",
    "Check for outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of categorical features\n",
    "Which features can be dropped?\n",
    "Which features may we want to complete/impute?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=[\"O\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How may passengers survived?\n",
    "\n",
    "What percentage of passengers traveled without a parent or child?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Parch\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,5))\n",
    "ax[0].hist(df.loc[df.Age.notnull(),'Age'],  alpha=.3, edgecolor='black', bins=[0,10,20,30,40,50,60,70,80,90])\n",
    "ax[1].hist(df[['Parch', \"SibSp\"]],  alpha=.3, edgecolor='black', bins=[0,1,2,3,4,5,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze by grouping (pivoting) features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Sex', 'Survived']].groupby(['Sex']).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize feature relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(df, col='Survived')\n",
    "g.map(plt.hist, 'Fare', bins=20)  # use age once imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid = sns.FacetGrid(df, col='Pclass', hue='Survived')\n",
    "grid = sns.FacetGrid(df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\n",
    "grid.map(plt.hist, 'Fare', alpha=.5, bins=20)    # use age once imputed\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = sns.FacetGrid(df, col='Embarked')\n",
    "grid = sns.FacetGrid(df, row='Embarked', size=2.2, aspect=1.6)\n",
    "grid.map(sns.pointplot, 'Pclass', 'Survived', 'Sex', palette='deep')\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relating categorical and numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid = sns.FacetGrid(df, col='Embarked', hue='Survived', palette={0: 'k', 1: 'w'})\n",
    "grid = sns.FacetGrid(df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\n",
    "grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\n",
    "grid.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop poor features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute missing values (Embarked and Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Impute 'Embarked'***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_port = df.Embarked.value_counts().idxmax()\n",
    "most_common_port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Embarked'] = df['Embarked'].fillna(most_common_port)\n",
    "    \n",
    "df[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a categorical feature\n",
    "df['Embarked'] = df['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Impute 'Age'***\n",
    "\n",
    "Note: There is a correlation among Age, Gender, and Pclass. \n",
    "\n",
    "Perhaps impute Age values across sets of Pclass and Gender feature combinations. The median value can be used or alternatively a random value within 1 standard deviation of the mean Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting a categorical feature\n",
    "df[\"Sex\"] = df[\"Sex\"].map({'male':0, 'female':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Males (coded as Sex=0) in First Class (coded as Pclass=1)\n",
    "Age01_mean = df.loc[(df['Sex']==0) & (df['Pclass']==1), 'Age'].mean()\n",
    "Age01_std = df.loc[(df['Sex']==0) & (df['Pclass']==1), 'Age'].std()\n",
    "Age01_mean, Age01_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Males in Second Class\n",
    "Age02_mean = df.loc[(df['Sex']==0) & (df['Pclass']==2), 'Age'].mean()\n",
    "Age02_std = df.loc[(df['Sex']==0) & (df['Pclass']==2), 'Age'].std()\n",
    "Age02_mean, Age02_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean and std of Males in First Class\n",
    "# randowly generate an Age within 1 standard deviation of the mean\n",
    "Age01_impute = round(np.random.uniform(Age01_mean - Age01_std, Age01_mean + Age01_std))\n",
    "Age01_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the null values with the imputed age\n",
    "df.loc[ (df[\"Age\"].isnull()) & (dataset.Sex=='male') & (dataset.Pclass==1),'Age'] = Age01_impute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Perhaps create a new feature by creating Age or Fare bands (discretization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"AgeBand\" feature\n",
    "\n",
    "#df['AgeBand'] = pd.cut(df['Age'], 5)\n",
    "#pd.cut(df['Age'], 4)\n",
    "#pd.cut(df['Age'], [0,20,40,60,80])\n",
    "#pd.cut(df['Age'], [0,20,40,60,80], labels=[\"child\",\"adult\",\"middle age\",\"elder\"])\n",
    "df['AgeBand'] = pd.cut(df['Age'], [0,20,40,60,80], labels=[1,2,3,4])\n",
    "df[\"AgeBand\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually creating AgeBands\n",
    "\n",
    "df.loc[ dataset['Age'] < 20, 'Age'] = 1\n",
    "df.loc[(dataset['Age'] >= 20) & (dataset['Age'] < 40), 'Age'] = 2\n",
    "df.loc[(dataset['Age'] >= 40) & (dataset['Age'] < 60), 'Age'] = 3\n",
    "df.loc[(dataset['Age'] >= 60), 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"FamilySize\" feature  and perhaps drop \"SibSp\"/\"Parch\"\n",
    " \n",
    "df[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\n",
    "\n",
    "df[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create IsAlone feature\n",
    "df['IsAlone'] = 0\n",
    "df.loc[df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "df[['IsAlone', 'Survived']].groupby(['IsAlone'], as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab Homework 2\n",
    "\n",
    "Using either the Titanic dataset or the Pima Indian dataset, build the best machine learning model that you can to predict whether an individual survived/has diabetes.\n",
    "\n",
    "***Things to consider:***\n",
    "\n",
    "• Clean and transform the data as you desire\n",
    "\n",
    "• Summarize and/or visualize the data \n",
    "\n",
    "• Standardize the data\n",
    "\n",
    "• Choose 2-5 algorithms and perform 10-fold cross validation\n",
    "\n",
    "• Display a boxplot and select the best performing model\n",
    "\n",
    "• Tune its hyperparameters (manually or using grid search)\n",
    "\n",
    "• Train the same algorithm on your full training set (no cross validation)   ( model.fit(X_std_train, y_train))\n",
    "\n",
    "• Test the model on your test set ( model.score(X_test, y_test) )\n",
    "\n",
    "• Display the Precision, Recall, and F1 score metrics along with a confusion matrix \n",
    "\n",
    "• Be able to explain what the scores and confusion matrix mean regarding your results \n",
    "\n",
    "** A few things to possibly try to improve classification performance:\n",
    "\n",
    "\t\t\t\tclean the data,\n",
    "                impute or remove missing values,\n",
    "                feature selection,\n",
    "                feature engineering,\n",
    "                try a different scaler (standardization vs. normalization),\n",
    "                try different algorithms, \n",
    "                tune the hyperparameters/Grid Search"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
